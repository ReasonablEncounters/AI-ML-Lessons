{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(np.c_[iris.data, iris.target], columns = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\", \"Class\"])\n",
    "\n",
    "\n",
    "data = np.c_[iris.data[:, :2], iris.target] # we only take the first two features.\n",
    "np.random.shuffle(data)\n",
    "\n",
    "test_training_split = 0.7\n",
    "\n",
    "X = data[:, :2]  # we only take the first two features.\n",
    "y = data[:, 2:]\n",
    "\n",
    "X_training = X[:int(X.shape[0]*test_training_split),:]\n",
    "y_training = y[:int(y.shape[0]*test_training_split)]\n",
    "\n",
    "X_testing = X[int(X.shape[0]*test_training_split):,:]\n",
    "y_testing = y[int(y.shape[0]*test_training_split):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes: \n",
    "- Iris Setosa \n",
    "- Iris Versicolour \n",
    "- Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We should now take a look at our data to make sure everything looks okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 2.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 2.]\n",
      " [ 0.]\n",
      " [ 1.]]\n",
      "[ 0.  1.  2.  2.  2.  2.  2.  2.  1.  1.  2.  1.  2.  0.  0.  0.  2.  1.\n",
      "  0.  2.  2.  2.  1.  2.  0.  1.  2.  0.  2.  0.  0.  0.  0.  2.  1.  2.\n",
      "  2.  0.  2.  1.  0.  0.  2.  0.  1.]\n",
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_testing)\n",
    "print(y_testing.ravel())\n",
    "print(y_testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing our logistic regression function imported from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the initialized function and fit the data.\n",
    "logreg.fit(X_training, y_training.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = logreg.predict(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_rate(y, Z):\n",
    "    num_right = 0\n",
    "    for i in range(len(Z)):\n",
    "        if y[i] == Z[i]:\n",
    "            num_right = num_right + 1\n",
    "    return num_right/Z.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_rate(y_testing.ravel(), Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well this isn't that great now is it?\n",
    "## What comes next?\n",
    "\n",
    "Let's begin implementing k-fold cross validation training and see what our output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics, model_selection\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.80392157  0.66666667  0.77083333]\n"
     ]
    }
   ],
   "source": [
    "Z_cross_validation = model_selection.cross_val_predict(LogisticRegression(), X, y.ravel(), cv=10)\n",
    "\n",
    "print(model_selection.cross_val_score(LogisticRegression(), X, y.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_rate(y.ravel(), Z_cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is not that much better\n",
    "#### There are many different classification algorithms sklearn has available to utilize in a much similar way to what was shown above. If you're interested, try playing around with the following:\n",
    "1. SVM\n",
    "2. Naive Bayes\n",
    "3. Decision Trees\n",
    "4. Random Forests\n",
    "5. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
