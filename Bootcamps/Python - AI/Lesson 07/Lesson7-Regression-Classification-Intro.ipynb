{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width:450px;\" src=\"https://durhamcollege.ca/wp-content/uploads/ai-hub-header.jpg\" alt=\"DC Logo\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LESSON 7 - Perceptrons, Logistic Regression, and SVMs\n",
    "\n",
    "## <span style=\"color: green\">OVERVIEW</span>\n",
    "In this post we’ll talk about one of the most fundamental machine learning algorithms: the perceptron algorithm. This algorithm forms the basis for many modern day ML algorithms, most notably neural networks. In addition, we’ll discuss the perceptron algorithm’s cousin, logistic regression. And then we’ll conclude with an introduction to SVMs, or support vector machines, which are perhaps one of the most flexible algorithms used today.\n",
    "\n",
    "This lesson, <b>restructured from the first in a series of ML tutorials created by Daniel Geng & Shannon Shih (https://ml.berkeley.edu/blog/2016/11/06/tutorial-2/)</b>, aims to make machine learning accessible to anyone willing to learn. They’ve designed it to give you a solid understanding of how ML algorithms work as well as provide you the knowledge to harness it in your projects.\n",
    "\n",
    "\n",
    "## <span style=\"color: green\">Section 2 - Supervised and Unsupervised Algorithms</span>\n",
    "\n",
    "In machine learning, there are two general classes of algorithms. You’ll remember that in our last post we discussed regression and classification. These two methods fall under the larger umbrella of supervised learning algorithms, one of two classes of machine learning algorithms. The other class of algorithms is called unsupervised algorithms.\n",
    "\n",
    "<b>Supervised</b> algorithms learn from labeled training data. The algorithms are “supervised” because we know what the correct answer is. If the algorithm receives a bunch of images labeled as apples or oranges it can first guess the object in the image, then use the label to check if its guess is correct.\n",
    "\n",
    "<b>Unsupervised</b> learning is a bit different in that it finds patterns in data. It works similarly to the way we humans observe patterns (or objects) in random phenomena. Unsupervised learning algorithms do the same thing by looking at unlabeled data. Just like we don’t have a particular goal when looking at an object (other than identifying it), the algorithm doesn’t have a particular goal other than inferring patterns from the data itself.\n",
    "\n",
    "We’ll talk about unsupervised algorithms in a later blog post. For now, let’s look at a very simple supervised algorithm, called the <b>perceptron algorithm.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: green\">Section 3 - Perceptrons</span>\n",
    "\n",
    "<img src=\"https://ml.berkeley.edu/blog/assets/tutorials/2/image_5.png\" alt=\"\" style=\"width:355px;float:middle;\"/>\n",
    "\n",
    "One of the goals of machine learning and AI is to do what humans do and even surpass them. Thus, it makes sense to try and copy what makes humans so great at what they do–their brains.\n",
    "\n",
    "The brain is composed of billions of interconnected neurons that are constantly firing, passing signals from one neuron to another. Together, they allow us to do incredible things such as recognize faces, patterns, and most importantly, think.\n",
    "\n",
    "The job of an individual neuron is simple: if its inputs match certain criteria, it fires, sending a signal to other neurons connected to it. It’s all very black and white. Of course, the actual explanation is much more complicated than this, but since we’re using computers to simulate a brain, we only need to copy the idea of how a brain works.\n",
    "\n",
    "<img src=\"https://ml.berkeley.edu/blog/assets/tutorials/2/image_6.png\" alt=\"\" style=\"width:355px;float:middle;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"./svmjs/lib/svm.js\">\n",
       "data = [[0,0], [0,1], [1,0], [1,1]];\n",
       "labels = [-1, 1, 1, -1];\n",
       "svm = new svmjs.SVM();\n",
       "svm.train(data, labels, {C: 1.0}); \n",
       "testlabels = svm.predict(testdata);\n",
       "\n",
       "margins = svm.margins(testdata);\n",
       "margin = svm.marginOne(testadata[0]);\n",
       "svm.train(data, labels, { kernel: function(v1,v2){ /* return K(v1, v2) */} });  \n",
       "svm.train(data, labels, { kernel: 'linear' });\n",
       "svm.train(data, labels, { kernel: 'rbf', rbfsigma: 0.5 });\n",
       "var options = {};\n",
       "options.C = 1.0;\n",
       "options.tol = 1e-4; \n",
       "options.alphatol = 1e-7;\n",
       "options.maxiter = 10000;\n",
       "options.kernel = svmjs.linearKernel; \n",
       "options.numpasses = 10;\n",
       "svm.train(data, labels, options);\n",
       "var svm = new svmjs.SVM();\n",
       "var json = svm.toJSON();\n",
       "var svm2 = new svmjs.SVM();\n",
       "svm2.fromJSON(json);\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
